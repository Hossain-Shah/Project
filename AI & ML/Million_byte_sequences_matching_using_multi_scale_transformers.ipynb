{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRATh-46avZK",
        "outputId": "2ca1d69b-4780-47b9-9052-225af4780ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting MEGABYTE-pytorch\n",
            "  Downloading MEGABYTE_pytorch-0.1.4-py3-none-any.whl (8.3 kB)\n",
            "Collecting beartype (from MEGABYTE-pytorch)\n",
            "  Downloading beartype-0.14.0-py3-none-any.whl (720 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.2/720.2 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.1 (from MEGABYTE-pytorch)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from MEGABYTE-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from MEGABYTE-pytorch) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->MEGABYTE-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->MEGABYTE-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->MEGABYTE-pytorch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->MEGABYTE-pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->MEGABYTE-pytorch) (1.3.0)\n",
            "Installing collected packages: einops, beartype, MEGABYTE-pytorch\n",
            "Successfully installed MEGABYTE-pytorch-0.1.4 beartype-0.14.0 einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install MEGABYTE-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from MEGABYTE_pytorch import MEGABYTE\n",
        "\n",
        "\n",
        "model = MEGABYTE(\n",
        "    num_tokens = 8000,             # number of tokens\n",
        "    dim = (256, 256),               # transformer model dimension (512 for coarsest, 256 for fine in this example)\n",
        "    max_seq_len = (512, 4),        # sequence length for global and then local. this can be more than 2\n",
        "    depth = (6, 4),                 # number of layers for global and then local. this can be more than 2, but length must match the max_seq_len's\n",
        "    dim_head = 64,                  # dimension per head\n",
        "    heads = 8,                      # number of attention heads\n",
        "    flash_attn = True               # use flash attention\n",
        ")\n",
        "\n",
        "x = torch.randint(0, 8000, (1, 512, 4))\n",
        "\n",
        "loss = model(x, return_loss = True)\n",
        "loss.backward()\n",
        "\n",
        "# then after much training\n",
        "\n",
        "logits = model(x)\n",
        "\n",
        "# and sample from the logits accordingly\n",
        "# or you can use the generate function\n",
        "\n",
        "sampled = model.generate(temperature = 0.9, filter_thres = 0.9) # (1, 512, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVtjvqIWbWS3",
        "outputId": "d0415732-8d67-48a5-e922-dd6f8ca7eb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2048/2048 [11:43<00:00,  2.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o-o2BJegm_X",
        "outputId": "01220766-bb73-4191-fd39-07215edfbc58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lucidrains/MEGABYTE-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQfCfXSrg1Aj",
        "outputId": "0151cb9f-0173-4777-f6bb-930c0acd0d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MEGABYTE-pytorch'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 127 (delta 46), reused 41 (delta 34), pack-reused 67\u001b[K\n",
            "Receiving objects: 100% (127/127), 35.31 MiB | 17.71 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MEGABYTE-pytorch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fACaAwhDop",
        "outputId": "3ba53d04-7649-4660-e390-b05ca2e465fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/MEGABYTE-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0z56boVhLuv",
        "outputId": "34b3c771-6b73-446b-b237-96818d5ad518"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n",
            "training:   0% 0/100 [00:00<?, ?it/s]training loss: 5.713071823120117\n",
            "validation loss: 5.336212158203125\n",
            "training loss: 5.33056640625\n",
            "training loss: 5.09693717956543\n",
            "training:   3% 3/100 [00:10<05:25,  3.35s/it]training loss: 4.7716264724731445\n",
            "training loss: 4.6202287673950195\n",
            "training loss: 4.4048309326171875\n",
            "training loss: 4.325751781463623\n",
            "training loss: 4.313610076904297\n",
            "training:   8% 8/100 [00:22<04:09,  2.71s/it]training loss: 4.081308364868164\n",
            "training loss: 3.9244985580444336\n",
            "training loss: 4.142832279205322\n",
            "training loss: 3.8375444412231445\n",
            "training loss: 3.88970947265625\n",
            "training:  13% 13/100 [00:34<03:46,  2.60s/it]training loss: 3.8636796474456787\n",
            "training loss: 3.9575092792510986\n",
            "training loss: 3.8612284660339355\n",
            "training loss: 3.812952995300293\n",
            "training loss: 3.762855291366577\n",
            "training:  18% 18/100 [00:47<03:31,  2.58s/it]training loss: 3.751217842102051\n",
            "training loss: 3.5878899097442627\n",
            "training loss: 3.682279348373413\n",
            "training loss: 3.5478007793426514\n",
            "training:  22% 22/100 [00:58<03:23,  2.60s/it]training loss: 3.6956663131713867\n",
            "training loss: 3.5798206329345703\n",
            "training loss: 3.6526365280151367\n",
            "training loss: 3.714820384979248\n",
            "training:  26% 26/100 [01:08<03:14,  2.62s/it]training loss: 3.5237808227539062\n",
            "training loss: 3.416811943054199\n",
            "training loss: 3.4033803939819336\n",
            "training loss: 3.364743232727051\n",
            "training:  30% 30/100 [01:19<03:03,  2.62s/it]training loss: 3.3658626079559326\n",
            "training loss: 3.3508951663970947\n",
            "training loss: 3.3390908241271973\n",
            "training loss: 3.444051742553711\n",
            "training:  34% 34/100 [01:29<02:51,  2.60s/it]training loss: 3.4251911640167236\n",
            "training loss: 3.2740330696105957\n",
            "training loss: 3.1347107887268066\n",
            "training loss: 3.0808660984039307\n",
            "training:  38% 38/100 [01:39<02:39,  2.58s/it]training loss: 3.175313949584961\n",
            "training loss: 3.14412260055542\n",
            "training loss: 3.1863842010498047\n",
            "training loss: 3.1528897285461426\n",
            "training:  42% 42/100 [01:49<02:28,  2.56s/it]training loss: 3.183197021484375\n",
            "training loss: 3.0456504821777344\n",
            "training loss: 3.130157709121704\n",
            "training loss: 2.9783501625061035\n",
            "training:  46% 46/100 [01:59<02:17,  2.55s/it]training loss: 2.9614033699035645\n",
            "training loss: 3.045419216156006\n",
            "training loss: 3.034440279006958\n",
            "training loss: 2.9858598709106445\n",
            "training:  50% 50/100 [02:09<02:07,  2.55s/it]training loss: 2.980008602142334\n",
            "training loss: 2.8587076663970947\n",
            "training loss: 2.8375277519226074\n",
            "training:  50% 50/100 [02:20<02:07,  2.55s/it]training loss: 2.7649669647216797\n",
            "training:  54% 54/100 [02:20<01:57,  2.56s/it]training loss: 3.0090231895446777\n",
            "training loss: 2.894317626953125\n",
            "training loss: 2.874875783920288\n",
            "training loss: 2.729938507080078\n",
            "training:  58% 58/100 [02:30<01:47,  2.56s/it]training loss: 2.873469829559326\n",
            "training loss: 2.795806884765625\n",
            "training loss: 2.999882698059082\n",
            "training loss: 2.7918663024902344\n",
            "training:  62% 62/100 [02:40<01:37,  2.57s/it]training loss: 2.657256603240967\n",
            "training loss: 2.7039413452148438\n",
            "training loss: 2.702983856201172\n",
            "training loss: 2.6461520195007324\n",
            "training:  66% 66/100 [02:51<01:27,  2.57s/it]training loss: 2.937713861465454\n",
            "training loss: 2.5862619876861572\n",
            "training loss: 2.711139440536499\n",
            "training loss: 2.635282278060913\n",
            "training:  70% 70/100 [03:01<01:16,  2.56s/it]training loss: 2.609724521636963\n",
            "training loss: 2.5418429374694824\n",
            "training loss: 2.576641082763672\n",
            "training loss: 2.523350238800049\n",
            "training:  74% 74/100 [03:11<01:06,  2.56s/it]training loss: 2.619699716567993\n",
            "training loss: 2.5448482036590576\n",
            "training loss: 2.5404908657073975\n",
            "training loss: 2.4841911792755127\n",
            "training:  78% 78/100 [03:21<00:56,  2.56s/it]training loss: 2.474133014678955\n",
            "training loss: 2.4962801933288574\n",
            "training loss: 2.5725319385528564\n",
            "training loss: 2.506500244140625\n",
            "training:  82% 82/100 [03:31<00:46,  2.56s/it]training loss: 2.5485475063323975\n",
            "training loss: 2.616539478302002\n",
            "training loss: 2.519011974334717\n",
            "training loss: 2.6755213737487793\n",
            "training:  86% 86/100 [03:42<00:35,  2.56s/it]training loss: 2.5523440837860107\n",
            "training loss: 2.5774784088134766\n",
            "training loss: 2.4596991539001465\n",
            "training loss: 2.5185251235961914\n",
            "training:  90% 90/100 [03:52<00:25,  2.56s/it]training loss: 2.697348117828369\n",
            "training loss: 2.5830719470977783\n",
            "training loss: 2.4951019287109375\n",
            "training loss: 2.5593032836914062\n",
            "training:  94% 94/100 [04:02<00:15,  2.56s/it]training loss: 2.4606406688690186\n",
            "training loss: 2.496351480484009\n",
            "training loss: 2.4652180671691895\n",
            "training loss: 2.6980836391448975\n",
            "training:  98% 98/100 [04:12<00:05,  2.56s/it]training loss: 2.48876953125\n",
            "training loss: 2.466642379760742\n",
            "training: 100% 100/100 [04:18<00:00,  2.58s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MEGABYTE_pytorch import MEGABYTE\n",
        "import random\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "\n",
        "model = MEGABYTE(\n",
        "    num_tokens = 256,\n",
        "    dim = (768, 512, 256),\n",
        "    depth = (6, 4, 2),\n",
        "    max_seq_len = (512, 4, 4),\n",
        "    flash_attn = True\n",
        ").cuda()\n",
        "\n",
        "\n",
        "with gzip.open('./data/enwik8.gz') as file:\n",
        "    x = np.frombuffer(file.read(int(95e6)), dtype=np.uint8).copy()\n",
        "    train_x, valid_x = np.split(x, [int(90e6)])\n",
        "    data_train, data_val = map(torch.from_numpy, (train_x, valid_x))\n",
        "\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "\n",
        "SEQ_LEN = 8192\n",
        "PRIME_LEN = 100\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime_inp = inp[:PRIME_LEN]\n",
        "prime = decode_tokens(prime_inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "sample = model.generate(prime_inp[None, :])\n",
        "sample = sample.flatten(1)\n",
        "output_str = decode_tokens(sample[0][PRIME_LEN:])\n",
        "print(output_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONoKTpEwak5l",
        "outputId": "9150878c-3f5f-4c8f-8341-05bc43d3e68c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%s \n",
            "\n",
            " %s (\"l have a male heir despite his wife's previous failed pregnancies (one stillbirth, one miscarriage a\", '****************************************************************************************************')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8092/8092 [04:20<00:00, 31.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G! tã2î  Tç !°Ýíì & ^ÄQ Ó-} ÿoÅÂý J o ·h ª W© 2r}\\I=r· E1  ¦Ln»}0= aV.Ä}yHÉ;/ë}¼HD dWÄÎKµëÿeÃ ´ ßS¡  \\µþAEô £Ó òëòÈ3 GCË) ¯Ó   µeDÂ~ûø«K ç Glâ¿+àNÂ  ¦T&µ0ä!¦ µlÿ ºµ/rGþ} [Ý V[IÉ¦Hh©ú6õUVHÎ¦(Ó} >Sõãó|6¯2¢6¿2¤¦òÞ 2ëQròl¦¿5Ý\"á:I=!8À´  CöI[b¥Ùf/ròílÖ²ßÞÉÝ}æ ;/;h²  Ä/¦²ýÿrG'Àß ì«!Î}ª8¤9ë  Æ >ªrõe¾µ» Aë'~Ó ´Z ¦½b/Â ß= 'eÏ Éü!=É  EK~t¥.C  Þßm ó! ´ÀU·¤ Ýr)\\ëåoVMµï~XßRßå¥M[eª;f¢R YË}òh£I= µß|¥r²DQl\" fWÉcå½âryî¦ßXîÿÀß ÉÀû´Àîí¹Î· Ü  Þ'§  ·LRÄK^)ôóO®È2g ¾ßwDr²î/;l û ¸Ëe¿W£r¿ÃÆ5ÓXV·l}) Ó |6½}ôßü6¯/\\5ê Qçü}ßwYâæXz© eªn OU,Tô µe£ 8Sj5Kµ=  í}¿ µ;cålPÿHûl  R^HÑ©  À}úò ÿr ô¤ ~å á ÓâK ) ¹Ä? úÇGmí 5[`) á  æ-r/ô  Ä°ÆfµVô°=À[OÉ ²û¡º Ó=ª8+îTcNôÃSÞ¦n/Þ¿ Ó´¯G ràýoÀáë' Gà} ÀU:2ÀÖc°ÑÕ.¨Ñ åol  $eò  ^©re!/cIÉ .ût .¨=Ç5âÉcb)¥Ñ}r]¤©ÇeÕ Ó ÷UÀ·YºKÝ6ô}Aÿ hi xÎ^ýÞ¯þAç¯¤ ¯·¤ 8WçYòlÉ 5 É }µG!Ä  ÜYç þN¯þµÄÖp«ÉÀ&Ó Ú· Óc8=å2£  ôk¿5 âúK¥ ^])Â¹´¼Nr³ $D\"3ÓÉXüS rG=ß5Óâ`mÞr¼õ/ ãüÄL  í­nù.Ô ¢ ÇÐVÂ >ªÀÖµ» 6e!¿ ç  $Æ8ýÿr¼O .  áÝWDÆÄÂ .Ð¦û=Þ3Kã ÏÑò ÝçrzòëY$K§[\\æW¾Ô ô)~þ} rò§ \\á)Ù/- ìÑªex=Çá½DÈîO¥ÇÖl¦È^©V.µ= $ð ªBüÞ\"KÓ_ ìÉ gtâG²r.bØ\\5ÝçÂel¥ »o¸/^Î KÓ-ªWø¡îx VHûlÿ2l=I2Ó T8+xßåxÿã  È§b/ Kú;¦2ú}  ÓT5à`W¾3ÿ«¥X·ÏÞ\\t ÿÀÖOxOxR ´À/¯Ý Æ~þå}¹g7 hI}e Ã)K ÿ¦Ut  Ô È Óâµ-Â»5ò!B¥  ì¹  ¤¦ W §å /' òg ¤@ãSçYE9göG øÈ bòrpûæUÀÉ¦ò G8WøG ^ZKU©l9ªÝ¨¹ésåÿÇD^/ bòí]h¦\"Vô¥¬ÖS ^2^/-&e I k¯1ý Þ Ómô²xÇeÝ/ÿóýo) ôÍ)½àr Aòí2 l§2û¡º8+Ñ j } fÀo  ayÀ¤úg=´ôË  µ K[Óx5æ£ÉU·|ë¦ m  CÀ\"½+U«n¼ô À ÀUõ6 6lÄ~·I MÎ6Ä.e} UeÉ¦¿ ÄÈåõÄ å}m=aFlâ ëQª îÂ û ­ßlÿròg7g3Ó ¿HôÔeG§ãeS\"  IÓv·ü£  ¥r°a«ÄCÄ D Ë) ÿ-»ª  âHòrDÓâV6Zx Ó ÚÖl´5Óÿ\"î£ UíîÉ8å~tlo~ /Ä®lÉÀ Ñ uå¦¿ÑÆS6\\3 É ågo\"2ºm)8µDß ²6¿ )IDl  w  =QÆxí $wÿ êõ\"ß ¦WÉ ²-r8SÿÇ$lPrnÓç ÚûÄj2g\\h´V¹hø bS\"ªKÓ\"  µ=V |)MpRµÑÈ l¥ É) }  ^òE,3oràbo\\å½Þª(Oø«GæVn g@þe$ò6øÆãÕ æGÀøá²a8À9& ãûl\"2CÉrñÉVòmÄ  ´ú!ÄÖ XYav.ÄxÀ â\\, »íþ\\r&l}­&lí 2^ì ñô)Àyb=!. P¯ ¦²) IÿnGû Æ Ó}Z(Wñô  ë0Mÿ/¿ìÄ cÑòV8 o îâ\\ÛPÉÿ8b\"YFc~¤æGÑò (½°  ô ~ JçV-ÈK~ú¦K í 5õ  5 ª útß ú9® )   6\\exÉft/-½º \\5Ý´V e}r µ£& ÛU«ÉJ9c[® =)Æ ß=rn =¦n úI¤Æhµt¯ r¥ÿÓÞcÃ~þý ~5Óm¦(ý} 2g7ÂMå¥¦bJµæÓ ) Àk$GÝ¥`  K²Îa4»|ÄUåü) 2Ó ! ²DÐô}µò d[ëÉX8+à æß½¿/;°ÅåSq#5YtrX°  ÓâD²þ í·âxÉ Kÿ  ûá83ÑKÝ ¡µceüß ø  ÓòªnÓ  À)c¹´ å£§  ÿµW/ 6hÄ ¼C6 ²ÀÖ  IV ßÿ»  G dÝR&6r ù+)½ô}  lÄ4 Yó 5ý/ú h yå ôã½o¦¤ ÔÙ µbøß5I  ëUV ûÞ¦Ôræ¨ÃD²ex _Rm8=È /«û J²Õ!2ë,Â·Ù/; ®masr]l}#cP¦Äí/I= R\\XhÄ\"mYÃ  áÞ¥B¾É;+äf ËDV ßÆÏynÓ}eÜ¦ß   ÉøK Ä G\\TÄ ÉÀÉ¿åPrp /  5ï  Ã ¾ïÍÿ·h ITÓéó|â»Óg´  ¦nEr:JÑEòb/rÐ[ fl¦#R 8¼ÿyG ãDh . cÿµ#ì ý^ G r'./­nù¦X]h,ÿ z À ÎÄ¥òá6ü >/rÞIÇ öWQòë6DGh¦ .¼ ~µDY6|x5Bg$nëU e¦ K  þµx«Ä\"KV.¨V»Xh}ª'W£Ó IgÿHûp~òýÿ» ´ú þ,ÚÖÀ¤|Ká  Výì= åô´2TëDûÝ ®ÿ$KáÄ£l;&DÀ'ç=mEïV²[ª ßV¹·ârË ¹µ8|}  C'í¯° 6 ª8ýÞ ®IÿºÜ¥I~^]eÉ [ëÿÖS5dmÍa!Ï}\".]kõ´ cë úÌK}yò Æ¸Kýr²C¦H6¯ãÓÃ õºKrneÉcµr·¤ Èò=Àe¹¥Äb\\íÐS5% Ë5ËJ}µ²lô µt¬¾ ¯5®k¯ySò\"5 Òô2Y´ ¿ / ¤øsáw´úcÿëDúËÖXO£EØüÉU²W©§Ð =o&°=Iß5ªng=Ú·íÑm8ýçé8¼¦È.¨k õ/rà YÞ¼.Ð/\\3å  pë%WsMU &wÆ · ÞÉfZ=#ë,THÑÃ ²¨, $+¥M ÑÉ¿Ø¹ôã VºGÑëÚ·ëÿ2ýñ\" úhÙâá/O'ã[~©ãTøÿWø 3=ßpAç $ðÍ  Z=ãXl})ªlòr/^© ~W©5lç æÀ¤ôBWÄÔ gÏ5[tº8ñ/«¼ÍÞª2htÝ ­y \\í  ²Olß5[  Þ¦nî  eâ  Êò ²Í [E9â6e¦DVå¥ 2À ÑAt'Î=DþÓÞ\"'Éc¾4'~²ôü@Kë ÆÃpºëßmà¡  Ó/ôåüKµøÉDûçY=Eô.W} D·ªxÉcålN¿ 6ºCÀã   ûÃºý¥ ç; S    2eÂá¡vmû E !Xe ¬æ£É åtÿy°   q6¦XeøÀ ô=)²ü ÿ   · ç  7¥¦( øã[Ý ê$  8Wø\\ Ó ¾3 \\µ¦ÿ©Wa ßÂÆµx@5Âa 6÷,À eÿ¦½µ  G= ÿ ³ªà)À hÉ¯bÃÿgÞ uOxß·ìy.Ä;þQ\\t¥}# ª Sí\"äÀÞÂEh´V· $ß6÷ÓÇMlò fO6  +}\\XlÿÀÓÿ¬cÿ·LxD Ô re )\"K²=ßHÀÃÆ s ÌìcrGâD r}ã ¼# b}r&l ælçÔßw ßbÉ¿çY»ãÙ } ãÿ ßÇ)¿ bë]S ËDë ÖSÿ  ÞÀ[ÿDßl§ Ko)Beî x£/ï Y/¯QV1Î}  Å¿ =Ñª O rngÖ .ÐËúHD ¦2l¥µGëç  ²GQnWÉ ,[í Ó  bÿÔ[í/úÝ¤æÇ á/  Óo g \"K µD 6ß·ôÎªßÞñÈW Qp«¥ÿ°} \\cÝ Þ6åïÿá /­ò/ l³EýÉ¬:JcûlªnÓ¥  å\" Lç Ö ¥ÿó = EhxÀMÓÄDÄbì &úõÆ8Î 6ô 8U~ bÉßÝ r.÷ÃÂòáë' ýoKb¥QlÉßlÄQTRçXåxTG Æÿ·t'ß  ÆÞñ9 Gû/1µV Öe}­ OÃ e! 5IgÖÝ¤ò (¤\"á  ª  iç Ý  ^XlPôò³¦Ù   Ð rÄ\"ºgò /Ó M }¿ Íü UÕ,  Ó£¦,Ã}# oß5Yâ gXYç (Ç·¤Äú[ I²C 5¸x ²xß^ë}ÿÐ0öã²Ó-ÿ/ÛtÆà¤ßmwÉÀ[ É Ox   ³¿2ýñ5KÌF6Äú-ã Ó¥üÉ¨©À3}¡âHÿBgÉjæÎ\"  µ ÇTbßw©É¯å} y /- À ÀUçÂ~þÉrµô)r Yc!¡ 2#5åë ß  ) Wç@GC=­®ÚþÞ¦ÙSL¯µÝ£Ç5Kë |~8Ó}µ#|/Þ©I ÀÐ~) Ó´8~ Éb£ ågÖ«KÝ=É¼h·Wü 2  y xTËJe 2©5æ8S, .µ\"ß W} 5|¥À[bo¦ÙS]  [²ÕUUnê°ãnëUV6b/ÿßl´ ceü©^ KWoÀý  b£rp°¦È Àç SO¡¯GÝ¥`²D  BËÞ% ¹árõ°ÐÀÖ µfyç ²û¡ â¡Ú(h 5ÝÉ DRÈÐ¤ô=Þ &Í  2^ ITÄt¦  ÉÀh¡!°ÿ¯ÑÃ)·bD@ãh^ÿn°= yx/ÿ3åë pø H  À[rnîÉ ßÌ h   ÓÆ¸ñ°\"&^ FDR ÐôÎr  bÃ4Gë6¯¿ì¦ÆµøÞþµDYßmg.ex ]ù ß2!øáÝ Ë\\;¹ôGO\\¦[ÓÄr.bx ßÝ¥/GC=´ Qÿr] )Àpâ &©É 'W}©ãl¦ eÄí]µrúWÿ·üm¦T¼ yÛ  Â¤ö(ÿo Ðß}ã8w Ö q[Æ'gWÀíRÄXHë­ó¥K  ½ªI \\2¢\"40ß=3ô  cëïV 9 §KIÝëD åÉ O£þ]Nçv Ý   ÍÿÀ[Ó -}W¥ KI±W¾ÎìÂ ýøÞòh¦á/ üXßÆ Ý²Þ´ áOãiø ÓR1&°T.µ£VålçYKµÆ .|tNg ÜGá} 8ÜÄ 3eò6UbgÞ'k¯ßQayh´  ÍÞ åÓ ¼Ï Ý»ÀãCë5õÿº]Àí/ °î .ÐV­ 5¸Î}y·ô}yn»V áít¦òe³ÂqSãVHí/#·ýÞÿ.¨õÿÓÿmý Kë ÚXÄí\"Kb=ßK¨}r õÄK âÆÉ 2ìªrõý-åBL} ;¨} Ýâ Ýb ÈÐxßK íÂ·h/cåxD2Ë }r· ª©ÐªrGOxÀMh£E c}ÙÜë ßÿrµÏÑyGµ~ÇSò Hêcå[Î+  ß)ÿ/ÀíÂ Î»6h£É8!=Þ½E;e  Yÿm2e³Tå°=S5Y ¿[|ÀXe! ýÇçJ¦ôå°5&Qª±Ð !UYÄÀ[bÿ¯Xô¥ 2¥¦TýÉ Óò¦áh£rîîÿ ë}y°Â Í 2  ÿ J À3ýø\\XôV1¬lü#=Ö[Ó£rXà}­ß ò)MìR ·It ! æ±WÄbþ¦ìc·bø\\ÈÑ}ø ,} y Øòí=ßT ¦ ²CQ=E;ÐýÞÂYo¸Tåÿ(OU!UÀ}ã8åo f½ª\\2¤  =É°ç,jQ}g¿óÀÉdåÿÇ ÷ÿ |)r.h Ýg  Úí}· ÀMÓÿ  µ£¦nb·Ï/ $AßÙ\"Ú e¦TÝÉÞò É.°xVòô°òe ÀëããÙ6ÿKÜ º üßDËÇ5IEÀ5Î ª8bÿDPrø¦ ®'dÃ°)¿/¨ ßX WR  §  (h 6ºëÿHÎ= 3ÝëQ hçm§ÀU Üëò» üH¤6$ R YÄIå\\TÉÀÉ  !¤Ç å\\ G«Kl= K²ÖVüìá½ß³Â¹^¦  Àí] bøÉ$D}#µ; Ü =Ç.  Þ ¢Ï à  ¹°ø  ôTÄt$òç ¤ÑÚbÿ»A¡) Óç |çrgn/üÉÀUõx)  ª¿  Ï= Y¦(D 8 Ëç l9ña­W\"x2Óçé \" !ßª2+lÉ.eUÀ ¾  ú} cô=Â·çË&nõU 2íëß!Olíex ¤Ä  ôª b/©þxÃÂ2rlß e})µOòô=K Kì Ý£ rX ô y  õWDþ ÑºeýUr÷þV?Kb rWN ÓxÿÀÿ«ºlU 5¸°j QÚD À2ëQËDR N=}«2ìÂ O¸TÝ/Ä¹ Gh£\\ü±ãx£ñ$¨k2 - ; )À Ä¥ (Óâê2© q ´Â¹ûU Nÿ y  ë.aRÉµí»hòe[íQ8t\"áÿR pkr Ô 3~h ô5Ã ×oÇ  cJç¯2¼¦¿ÉùÇ(l/­¤$# bE,XOx  ¹%5 7g3J Àô}r.£ÉcO/rò  æ(b-ªK \\áK=å áÿ·¨Þ / Ã ~ì¥ ;/ôñ}  íVýUht¬ex´ÿ O»ßqªVH  BñÌ  »4 Íl .h£ÇG}ô ©/r h´ ßK Kê=?Úî}«]¢}æ°=¦ÄÎXV=ýU\"ÑÄ/cûÄÖ!Ûo~2hlÀh´Ö  ß¥V N\"Ïçr \".Íl\\5k¯µ Þ8 h j y   ý8µ}\\2  d8~EIK°ø Et  b£)  ßVx=fy¹á  ´ÿ.÷= Ý d r.öUÝW=é°àVx}öM ërlü Ã)Æ8ÓâK°50ß ÞÄ[í©në r }) .¤òáOÀ\" b8¼ñz'C\"ªçéU¾ ýÿUÆ GôÍ 2ge8J¦rú tßm¨oèÍ©ßTÄ½  ë/rygc µÉµ 3 ªn°Æ·²'-S©rG! )gÞ¥UÀk Ký  6x y iÇK²tÆÉÓxÀ&/ ¥iâøngÖcåex §C 1 =¿þ Æ©´ 8Tå cõt £Ý   Ëç´ Z IK~V~²¸ë\\X)ô £ G§ÿ  l~.Ä~ ¹ûP¬e-rà²t.eU\\eò þ1V^Ä û ­'ÀÃÆMû~8 ½¿Kbr]µç»þ^ç  K'«ß^^¦Üø¡5ËÓmô øÿPÓ Ç ÕUIÔxrÚeU;WÀø#·iDRò¥Å·ÐÉ C/ÓMñÌ¯y®õã=ÑÀ3 : W£ në6ÿ ½ÃDØr÷ün°âòûò a\"®Ó é/ oTO 6½=1 tâ2¾OI'xmÂqÓ) Y|-\"EÕç ÀÖÇ¿+µ)G!ÏÀ ý^È.e³Îò¤ ypRçÀ;7²§£);ëx\"2 Ò ~²ÎIÓYò\"El} nëëã Ó d5=Éc¤1»ÞÂ¹ûÉrß\\ylPòh²\\æeø ÀÝÿ  }2ìh 2^^V·  y3/ 6ü ÞFøò.û .¨`Þµ ÇM ¼#å+ò¦ò¤É ãb\\Ûó Æ\\5 ¿K âm`²DpÐoí]RôÎò l È.Ä 2ì EK Æ=´UáOI'}Ã4òh´$)«òYÀ5e GÑñæÄ Ä=­' íÿK§ÑG¢ ÿÏV!^É»[¦Iâ t\"G oÀ áÂØÞ-µxR Ý  5¸$ò2W»Ó'g7¯ÓRe2ì})KIÿÀÝ GÇhYÂþYEÿµ¦ ·Ù ãÓ¥K eD² æeÿßw^©ÿß ¹­2g-rµ¤mV1O<­ À É;¡  tß+ ×7e /&ª qV\\óµÐ·´ y Ü\\r) /YçVý~ ¿~l= ©Ñá/ùür·L´  Ó W6ô ) høÀ&°¦IÀrò3ÖÇÐX\\ K   § r]íªÿó±lç ´Vÿ ¾µV1+ü¥ .t [©/-Üÿ}R    ]£Í ªbDVn¨òâ ·  ôýò ÐC É2 ç $òª ú¾ WDß]gòzçÑ6ÄÖSxãeIøÈ§û¡ºßbò»XO  ÞÀ w°VÐÓ} [´ÀVôøÉi n \" 2Ó/ Öeîÿ Î  &á chRÓáµV\\KEEØà~ÿy¤ \"B¥ü  ç,$ÀÉc ÝÄ~ó·çKÜÙ´  í¦TGÑ©m}µ´òáÿ  H£)Ö  ü Óÿ5®m  ÜE9 ò MÀÉdßì¯Kt¦³ÎE ãK'6 =ÚÐ¨Þ© Þ­ãätâDl\"oõ°¡À¤xr]l Ý  G!Ëª]ÀÞ©cúd]é¾¬ *ÑÚ/ôÃ  Ó ÚWsÀPç+Prp6ÿ2ëo¸2 ^cË÷ /Ó ²µ\".à`Ég}r.ÐË)z6\\Èþ ~  HÍk$òe} ÿyò£©þÓ¥rò  É ®ÑÿÉ Ë[©^Âceª\\.aößÀÉ¯ít¥ ü}ô!=1&ªò áíÂ¼Vÿ åë õÿ v2Wr áÄ?6bÿD[ôV® Y õgòªnlòe gt¯âgX¤x}]U \\T¦Jh£å¡Àb\" p¨ÞVe!o¯ DÃ^cô¡M 9T.ûK ¼¢åTSLô$Ó 4 ô ¯â½Þ¯y¨}Ræi)µÙâV·CÀr   VÕë­ ¬ Y ¿.WNr[ÙVe! #É|æ2lß&m£ ·Ð=­|¥¦lª  ÝÉ:K¨¡ÿH´ºz¿[e  ¾tßQ«8S»ßmìc'Uá°\"5ÝÆ.TÉ¦Ùí  ºµDR·   -Â~hÉ J 9Ö6ô}\\GýÉx$³d IëV.¼L¿w´ åDÙâ }µV ÉrµEF¼    õÉ¯|=ÀMµD G|âæ8À ÞöþµÄ ]Iâ)î·¹ îP We=o°ø¦ å°»· ræ¤ ¯.eD\\$NÎÐ\"ê Ü/ nOpd8Sí­n6RmórßwÙÄÀUYÞÉ[ÿ/ yÿ w2~ ß5êErçreK\\ ²ß ¿ÉÓP©5Ó´KOEHJ`)µ#ÿ MSõ±¹|ÿ  ¾Ñ²\"rp}} . oKYÿ 8Wø$¥'ßÞÀÎRçXhÉ Óç\\Yâ»ÙÀÉü ÜÄ þ Ä\"áë°YÄQ;a¦\"2 Þ 2 üÄß}»© çEë¦ô ÈÝ À ©ÑtªdÝâ C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(list_of_strings, pad_token_id=0):\n",
        "    max_length = max([len(string) for string in list_of_strings])\n",
        "\n",
        "    # create emtpy tensors\n",
        "    attention_masks = torch.zeros((len(list_of_strings), max_length), dtype=torch.long)\n",
        "    input_ids = torch.full((len(list_of_strings), max_length), pad_token_id, dtype=torch.long)\n",
        "\n",
        "    for idx, string in enumerate(list_of_strings):\n",
        "        # make sure string is in byte format\n",
        "        if not isinstance(string, bytes):\n",
        "            string = str.encode(string)\n",
        "\n",
        "        input_ids[idx, :len(string)] = torch.tensor([x for x in string])\n",
        "        attention_masks[idx, :len(string)] = 1\n",
        "\n",
        "    return input_ids.cuda(), attention_masks\n",
        "\n",
        "\n",
        "encoded, attention_masks = encode([\"In 1965, Brooks left IBM to found the Department of\"])\n",
        "prime_encoded = encoded[0]\n",
        "prime = decode_tokens(prime_encoded)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "sample_input = model.generate(prime_encoded[None, :])\n",
        "sample_input = sample_input.flatten(1)\n",
        "output = decode_tokens(sample_input[0][PRIME_LEN:])\n",
        "print(output)"
      ],
      "metadata": {
        "id": "kwiHz_9PlzxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05f5afe-6579-4413-ad96-ea78e3f34a5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%s \n",
            "\n",
            " %s ('In 1965, Brooks left IBM to found the Department of', '****************************************************************************************************')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8141/8141 [04:22<00:00, 31.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ô ==ª2 Ç¯À°X Eú   ¥\\µë/ &²á b-rnoVògÄ  ºU\"G[ ø\\8ûÄ KÜ=?çýx  áÿ \"´ KÌ/ÀhÞ»NlÄrÓ£ úCÞ^cwÎ\"g  ÞÀPJW}ãþ\"ÆÒç  ßvKü6Ä²h=r ª©.Cì¼¿ÇòhK©/Y}h \\wª DZ} pSÿ@ãíçrn°9ÖTå¥`2úÿ ßmÿÜÝÉ MNa^²Ó-À&ÑÃN çÂºx $ ç.r}ò bl!S}µþl +LxÿHí }û;µÓÿ ·l}ÿß ÿ  |ñ«åür& }É´Ð À.Íp hÀ >ß  Ü }ypÐ ¿  Ã [î æû  x)r&Àí»!xÀ[bØP§´  |l§KÌÉ >ÞÂ~\\¿òWR 6Dñ$Ù) ·Ï}). 6¦HûUÈè  ·/¿ r rÚ¼´ 2h×öMÓ¡ ÉÀt ËWü]Z©ÈÐXxßò À[ITW)\\Gû ºÉ CÞ,i}rà(¿°}µ»b£À·ô ¸=¦3² ! b ÂcÑëVHù þÄt ·Ð Éµ¤¢ÿHÎ cxÇ Gb¥ [ë/ÞFÄ YÛK\\¨\\KÌ8|ëI:ílºKI}y²û [|ã:e¦ q·L-[ßërÈå !~}ÿ©Óò ®ßÿ GëUI ê}¿  9\\Ý}D µrX ¼/òÞ\"2ÓoßKÜ=!Xå¥j äÿDS6ßXå°¿KµÉrp°6  l¥ ÝJ«$ÿ@&²á¿ãbÃ cÿµÎ Â·¤ÄÀ3 /¯G|= Kî ZëYßhÉ¦·Â >ì¦I N-r Yÿ þ}© UxÇüÃ Vx È ´úÀ/¨£ EË\\c¤U) ÓâI(²â Kß]EøòGë  åÓ£ÂK oV ûÞ  åsZXHUr²l´nlâ  }µ2Ó/ Mµ«zý;ßK²¿8   p²/ôò ëIîÄr.h¡`ãx´áo  ÿµ·ú¦r W)®.Íâ C-)ùøÞ6DÂ ¤)gKìr·¨ æû E £ß ¢ ! ex ålÿDÖÓò\\KÜ¤!.}ÃÆ©Cç¼bE 5úÄ ÆbÓyGÀ¸8àte ã·eÂ lö¬YU' 5KÂ·¤ñ© úøòG  ¯2©Ó4 ²QNôV~[¼ÞÉ´eî nëÿ GWøndÐÿyx)¥ò ;ªÞÖlo5ý¦ÈÖÓÿî )ª þ  ÚeD!Xü\" þÀ' EbþÝÄ 5 Ñÿ QXà=¦Le¾ .W£ IÉrß^Æ©ßC=­g¦} fâêºDûò}ëQKý}y[êV¦n/)\\y°X¿~Çç (D´úG|Ér Ä ÝÀ\\ã_  G QÝY  =)c'½kV²º  Óì 2 Ï7}S} ûâr·e]I ÉjÑ£ÉXß¦rþ¨^µ©Ó lt; ÞÞ }.Í^ £   5©§e$}à \\ =xV6ôVå6 P¿Kýç   ÿÍÿ 2WRô3 o·øßK²ÍÀÖ¨ qW}ÀWø  S\"V8¼s [C Ýål'gÃ Ð}ã ^¥ ·\"´º°â¥K ý^^ Ä &ÀçÑþi Æ  Æã8   áD=V¹I   ýrê)À®Yâÿ.e  `QþÓ£\"= Eå ôGOø (Sÿ¯¿ô=Þ'ÎD áÍ}ÿHe£ µþ rHhÉ; ÓÿÀ[ xÿfµtâ |É [a .¤ 9f=  5SçrþÎ}ÿ»|çµôü 2 2 DcõÑÃ.b¼ ø¦ß ÿKÓ6 æýçé¹ rPÉ¿ ¨6r =Vnò À[í°8S¡  ÃßÓ/¶ c©!Kêø«2ÓçV+µâ5® ñ©¿þ   ûQrÓ¥¬·ßò ½>¯Ó Q üræ.¦r© ÇGÀo ãÓLje!¦EÚEØöç ÿreþøÿnS6º8S¥jªô}¯¸ñ b6'C/\\GÍÿ¯~t¬áO\" Ä/Â~¥ G~)Æbl Ý ør.Ð Qn°VÈ8WRX  ß b ÀeÓ y[ t¯Kxÿ©ÐXÀpA$ 6h£rP3çr·iK'.E}»ò¨czÄD·Ù å3·=QexªÄÂ¹å ÀÞª²ª Xà¡ fW VåæS ~2ýÌÚE ÞÀUáÄÂ²ô6åãÕ=Ç8 ÿ,ÙEV Ý qË²Dr  Î?  £ .¤ñ¼ TÄ«Äl¦$¡ªò ìV \\À Yç &^,ò¦6ìø3çY²öyÛÄlcåÃ'.û}  IoíO) åÄ  ý©) À hxT8Üa\\ªn ß=ût$KÓ  åxÑ« Ñ'òôò ¼h/ `²ªG|xÀÉü $(Iø  V ýo:út\" ©¦²ÕÓ: +¥KÌû?ÇâÓ TëVÿº3GÄ GÝëD Êå i r&b'ÉòhtÀC=¦WobrG r Ü£/ goúÌ[~ß·eÑÀ'r ~e°ph´I5êÿÇÝ Rr £Dræ.Ä~ßhkV®b-ª Í!5-r != KÇÀÝí\"ªòf-l ÓáÂNø !eÉ qÀÉ\\,3K\\ h} n£©Æá¨6 8¼Vr Sò  JKêG ê&° À3 Ü,ßÞ-´ Æ W¥VlËÖ²D-¥.Ç'õ} 5eî í¨­²tªGhøÞ2À/\\TÓRç·Ï ßãCÞÞÞ_E óìËª SÂ¦g}rZø\\ bÉ; ¥ ÏÀG¥ ,ß¥jy¨}r¼h áò  I¾^¦¿Ht ¿Dtÿ  ÄjE | ¨V.Cªr °rGû+µ+xÇndøI5½r]ü ª:üÑVý  À5[ ß=12høÈ í\"E / [ÀÉ|2Óâ °=ÞÖ K Í)ch²EÚë³¼Öl  Ó «´ âü Ñëï´õ7 °ò¥lö ýø G¦³ e¦TÓ £Zg$Jh¥ß5ýç» cgßKb¥ æÇî QpS»ß 5=#Gô° ¯ Ý  2 / !¤|Ikj²L 3,38 Æ\" S\"ä»åÞÚ   d  $À&ú (h Â¹eò lú MS\"m&h rH KÜø Mß=rà²î\"8 VXOûVÝÄ¹c/©  Üër Üø UáÄÀñÂ¼I-U2Wú'§ °ç@}µ   > r Óÿ GÄí¯ãm  Kÿ Äúõ  E4 ÀëD·ú KëQ¥ ½Ã1 r ¯) ²ÕÇ 3tr¼¹xªñ}0 ºðInOa® Ô÷ÂáOí /µÉ(OÂ.W© .}=ÉÓ= ²}c[I'XÓòrprµ É¦TÞé°a=.]ü¥§9Ç §ç5Wr]¤s?b\"DH³ E  QÚgÞ ÿ Ý'  Ó  =Ày°x À) ºëV.õÄÂ  ´ôüf}¼ ç Ý©  =}yç=Ñrnë¡æ¨oÀh´ô}R4ò|D¹Ù .»).Ý Iix G /-àD\"fÓâ^¥À[ô ·Ó=r& \\ Úº\" ñ$`  ¯Óë)·Ï á  =?òOø\\2h=¦òfs ²lc,ëU òhÄ~ãþ/¶:£Ë\\Æh}ß3b$µ·ýÞV·Kª ÷NØ'WxVàççÍP 6}©Æ·I¥ÇGZæ ßh ) À¦b °ç pAtß&^Q·l\"æßÑm G³À¤µVÂÆ÷6VÝ cwW= GÝ} pàÄ´ò¢ ú-fñ\" 5K~ò6½yJÎ þ ÍnÓ ­  ÓçÂ(b G ò¥ ÿµ¤  pûKÆS[ÆK~}¿+Îè)BÓâ¥eÝç 3lÉ SÉ NÐÄrGûò¦KµxD£) í³d[eR ÉýÉÀí¾Ñ}µë õ5~¿åî¦ÇTÝ´  Wë\\Kµ}»5Ý  ñDW©ÿßQ  yµ6\\8   /OíÿÐseIl\"m°/ûò ßÓ£]¤¢ çl ® SÆÞÓ  ò @p+\\ãßÕ»  Ò³1¬âÞ_l¥ßÞ½ÿ¯.eÑ feÑ¯K ýÀ'iÀXß¥ Vÿñn=o EDå V ìÉò°a\\5ÍçÀßwoî  Ä\"GK/Þ}  åPrµºÄLee¦æÝûrXÓ¥ èDÃ~òeU Ü ¯XO©ÿóø+ z±lð!¥ XYÑ ¬Vx®lâ 3 ÉüÍPr3KýûU\"áûò  Äß&lüÉòh) · ÏV.¨ N/ ²lo 6);O/rÈ ey V WÓì KîÉDGÀç«BÉ Vë ¿ Í¦áÒ³d·eÉ\\fÝ¦ .Ä£ÿ©ö}­6zo 2W¾òKIoVXÞ ´ °V ÑEï!}   / 8åë þA¥¦½^Ã©.Óâc  ø þÓÄÎå¨[êKµD\"é  ÚY úòü\"5M ^ |ÑVå£/¦KOl§[ßªÿ5ë³ 7b»·i»rÚ} KIâe§ç ÄîÿÇ8Jÿ8G °ãä!= Eålç½=éF/í·ÐrÝ âb È2+µ;õe}  [~Ç5GâDë 8¤|yÑñÂ·Ù6 /ýÞÉf K'r)ªã  'Óÿr xÞ¥ »ÂbÜ¥ßw   ¤Ý£FMNÞ% h cexc áx .·Rc!¦IßÎRç å£r·eV®hs¯å %   Þ[Ó ´÷³¿=6 G!ÿvò±^úÕÜ/I+ Æµh^ eÕñ«Ég' VîÄrnhtÿHh  6eUV1 ¡ºµ#xßÓçYß+µrcõçÆX }KÜ£ÉGZU\"5¸!¦!·© 3e³ ²Io¸åà ÿK¨r&lÄßñ¼\"ßùôlPD1¥U cb}\\Tòg!©x)õ |òhÉx'õÿyòe  Ýûa hÓ  z  ºïå£ W©ú 7²CÑEKW St¥iC ¦­Ó  2c} åStªB¥\\2ý0rGÀ¦ 5ìô3~Ç b¥ áb/© D¡VÙc$l   Xsz2ûÄ ßÎÄÎÑr l\"  Ó ÔnO- =í·Üxµ¤K·ý/\\y¤  |PÉ å¯¼¡ KWçMòf½ Þ½©Ó­2 ÃóºKÌKz×À,lËmÀ¤¦2ìÑ=»ýÄÿ8Îå  gVÂ  ÉÀb} Ðr\"KÜÿmßS5 ,ôR^cwÄ >ßXÔn°Ý =x/I©Ï2g'¦hµ» Yý}2gÞÞ. Ã~òeå¦L¼ÿ l©r zÄ«i¥r²ô ry¤tr °çY À/rG6rÎÐÿo ª/r £ 6ý/ 8Së0z)rZ¡) úÉ e}=ÆV·b À2Ó´}rVrî } 8Sã Y wÈ£Éj  t¡»ªÏ=ÉcJ}\"´ôÜ ßüÄK^}  ílz rn´ºU«t\\GôüÈþÞQpbD´üÃ [g7\"VÍ/\\îÄÖ(¤} ÝrR wà)vKÍa«2²6ÄAøðÓÓ£À3½íd8cÿÀ&A6á°/¸çKÌSç ª ç~Çh=á·úõ5~ÓK(ÀÖ¦½°¦Lh=»þµÿ  >ª5 iDªþ  6| Æ~ex)òlª  å'ã¯b°D1= Èò \\3bVÂcÿP  -ÉÝÔV1ß 6\":xª ]I 7Þñ ß ÀÖv.Sã1þ=ëËJ9rò ò ²O;a6S   ÀMûÄ  Û·Ð/áD '6´¨C ¿+Sí~û=r í})ê»`nÎ¦ÙÏÀþAÉ´O¥I  ¹I e I!ËR6·úxV·hE zSÿ¯âIÄÎ¾ ¡\\Ûgòá lª\" á ·ÏÿÎ^/\\áÿ@&Eçm8ñ}rH}&ò »ª7Ó¡  ©/ KYø#ãeÏÉUâc ©t4 òô­eÝV|) útK`Gë  6 æÎ¥ .e¡´X°Î\"ßÿ ^ htÀeøø\\GÀ'¯XxçE.Ó}rp Æ çÍ°5&£É)ª  \\ãÑëròü9Rß ¿ µ¦ÿHëgd[ÓòrnwÄ æ¨ å+a Ï ²yÛOr ¡Eò â#c¤ ÿ·í[ o $b-âK´ (ÍaÉ Fç ½í r©ÿyÆ·L¯yøÃ48W Mòbx eÀ&Ñë ·e£©5 KÂ·htrÍ æ^) Gª¿nÓ´\"G¾Ä EltªÝ É;a É ^û/;þ°» K ÓF¼N *òf¥j Êc!ýUÚNµÏ  lÉÀ2^$Xà}ñænKëøÿóìíÂ~¤ÿrG É;8õ )îëV²¯ÿº|Ä 2 ª ¤²D}r[îÿ Ý  /Y=ß²lò  lÉc ¾ ß½= pá ²k- Ioúî6 õh p}Õá ß|DSã\"eø Mþ4 GaÈKO ÿ·©´\" ëo W  5gÞ 6R6Y y¤Ó¡ú/µÄ´ »r I=á rø¦XxÿºòíÑª©§´Ö¿çb$ò8Ó-ÿµ; |çJ×rp 12£\\3J) N × -UGÉ xÿµÀ}¼ÖÉ (õÄ?·¤ È  \\«Ká ràÄÆy[ß5Iø5Gûl $£ÿ¿þý-©¿IÄÈ.Í q xÀÖÀª y¤ &úò ÐSò»[} ó ª 6  pôÜ Kµ»`òeyîWzKl À.¨8uWÆDû r/ÀÖVHûQÝ=çr5ýïÆTÄU ]eÄíÓËú5I'À²  Ú·xV ;xãþ $ò6g-)cltÀ[íåI Yâ 2CìNÐ= pþÌ!K \\r É  1¬còg}%[Ó/ 5 µ&°¦ÉßÓ «Ws 2ü) áOø áÝ}9^ñ\\òe c' ßAJúZâòhå7ræë¦nm¦ f½øÞ½  ­uî 4 ýxßNütÀßm} 5  cÿoß ûK 5åïÈÑ})MÙ$rWWÉ êÄr.ÓÉßXWçnãür]¡e}ô[ë ]ùÿº3ÝÄræe}© StÔì  /YÄ nWaß W© Xæ 6ü¥/l=É ª Û+¥Mc¤9ª+ýxV  îÀãÙÌ@&}6]Ix ¼Iø ²¦²û á /ë,3f´ 8 Ø\\ySçé Ä´ 8õP Àeòú=ëÿ» ¡`ù =ß&e}r²h=å Óx 5êÿÇ5Î ©þ}R¿5I=ÿ[e}) üÄ ÐôÎ KO ªngòÿó9TÄ¹ôÓÿæeî·Ï o¦²º ¿8Óÿß6k$,ªÀ Óò Ó«ßýè`  ¦bHhÞ­&Ñ)ªÔ lIÞ^/Úb) Oa  J)òf \" DX Ù=ßKAEç+âb¥KÝ=´ w a«Ä Ë¡G ºUW«BôÃr. .¦­ µ  §Í   û  ÖÍÉß  ®îø ã g¿°= pbxTGÀ[ß | »ËÝ   r·e¦ ° ròh¦ úÓÞÞ6gVºD} ,û Èòütª rÄ~ù´ÿ/^~·Ó6 Lý/ÿ5°£Dó V Gl ÆMhtßãñâú!¤ñQN É¦·;7Óòz³=ßQ\\Àà}%5½É åO5õx µÏXêKÜë¼òeÉ Ó¡µD·U ·úÉ µ; 'gC/¦©òh eUVDY á=ßKl ª.°ø¦ÓÞÂ.Íüß¥ ãÕÓ45dÞÿ/eÃ q} =Y y[Q5Ó ü8Ó´~ãÓø´Êùí¯2 ¥ [À£©5Âø uñ · ® Kl¡,Wo¦TÞ- ÉeÉµyS\"V1¬â ò =å½°´òW Æ6D  ß = ß  ÿne Â¹WøÉò  Q5[ÿr¼à=4N  r]Îaûòã ëÉreÓt¬´°ôF}#¤ )Ù xßKý ÿ 2í ÈMø¿5loí]ü¥  ÓRsx¥ú ÀcþýxV!ýø¦²Ílrîÿ ¦2W¾ ¸lßÞ½à ÀÄÖ8ÀVÂ= Ù#xÀk¿ åÂ²¸}\\f Ã Gh¥I·¤ñ¦ÏÝ\" ¼hçrXHVåxV1·h´  ßë%DÙ À&©   w¥ ²  Â~eÄQ lú  å ÂáÍÄÉò°øÇ5 [ Ð  À[¤) ½ÎªeJ°V8+à,f  y ù´ÀVå+ K¥\\eUá1ûÿ5bÎßm «8Ý 8|/ ÎÄ Kýì nîâæ  ·Ï) >Së­¦¥GC Q ÎÄÉU  Àg7«}ý} çJ)ªnÝíwÙ /Eø\\5ý¥ K íÂ·I}  ¾  Q¦ ¦ eV®òø ËWx)KlçGà(¼H o Ð[ræ ÿn59Þ[b/ Ýí/r¼eçY Ó¼õç=I'^©§áµá   3o\\TÇ¿©\"Ï·ýÆ©cÎå~Ý sy ñr Z´¯ã  À ö`»²Îa¦²ù+x °²ü ¿ c£ &Z©%õ }rò í\" ¤ÌnÓøâ2øÀ5bxíC'íÉ\\ KB ª r»\" Ñã2ëÿ»fáOlªOír²gÞÉÏ 1 ÃO¿2+c¦(DlçÝëNª Z-ÀK QãbÃÉ ß)~t í^(lPrHûP\\G|Éc_Ö K}RÓmßKY íHÉ´ tÀ®ýÞÂò¨\\TkV h©É ôÌ 6û) (gÃ~KSÂ S ÂåoeI-)ÙÍ¤2ìÉÀãO-(² Écë/   /ïHi ÿµ V®íî  =   Ó}y2ú VHÍ^ sZøÇ  â .÷})8c£ 6}o~w´Ð¤òKýxÉ ÏVòôV®Ú}ô8 9úþ¦ßh=v2sÀM Î¦Lrø nîÀV ¾bD\\µ 9´ ÓÄ~ßx³1»ÞÀhÇ }oßÓâ ye¤l¼NAÿÇ ßw^pàxÅþÓ Àµ ÙÄÖ29XÓ c  ø5K µKcÝÔ¡®lÄ\"Ó= Óx@8Ý 1¬á¦¿Ññgoí¯WD~²Í)ÿ NÞ /ù«&lðc, =Þ5õ=I·Ó  7KEl I'ôß+ -Énë]é~ÿ/ &eîc¤wç !Aø Gý *âê ÉøÇ .eçEÀ9R.Ä ÿe!=x ÃÉ8K'eø Ýí}ßXOoèÍ J ÎIñ/í·ô) Öý0c©R6åüì\"&úÉXüÞÿ Ý   £\\8ô r²$`  RrõîÄÉGÝÄ´5ÇÿmÍn»å Þª²ºo\\.Í¡  úÉK§x nÝÉ¦  ¿[Ý°¿ 9KÝ Â 6Ä¯=b ´òýoÉµß)KîoßTh`µ|xr.ÄÉ & ª.= rCaV·i©rò  V.û+  }y²ÕÈ2reeªÀ÷}D·e=rndiÂ nh¡À×= ²^^Ûeî¼ 9\\5ÓmÇ àV 2Ï \" øâHû)À' )ÆblªNôÉÀ !Ä~8w/¿  =fÓÿÈ Wx ªÓ} Kµtr²hkº  É¯7YøKK÷êÂ(²oÚNÙÿÇâWí^ µ}r· Þö3 ³jTåò [ÀÖ W}ö5ýìc/;Þ-}Sa ¤Ór ° ú ^=~X  2 U\\h ØKÝç»KÌd2ì=ÉÍ¡ Hë¡¯Ktª2h\"ÏÀVº5åÞ¦T Þmòh´~ °X KY«$²P¯XÓçV· ÿ» Îtã8ý^  ò ÙÄ Ý  »²ÍP Ùër.W) FÐ²DÃÆ ÓVD²Àëÿ5úÌ b£ÉGl¥Ç 8-)µ;Är÷\"V=ûÄ´ ú-'YÓÉ´!Î¦ò  !ÓRrHt¦I \\òë/\\ygEV=ýxÇE îy Së¦ÙârÚ×ëã·|lc·Ï}\\GÞ Ý=¿çÝ  µÉ Tr  fy¤ÓÞm.CoV µâ åf)¼¤ÿ MbÉd2o)QÆ¸KS6rßAE ëÄreI \\3ë  ÜÄ« ²Ô x©Ó·¤ÑVHK\\òf¡ °Sÿ¦áÓR1=É´X ©úÐÄ/) | \" åP#ãx #ÝÄDj¼ôÉ  4=À Ì 8  #,bÉßHêÇ gt\\Ó ÿ |/ ¼Yø\\5I/Iÿ ¾Oø4 ÝR (ÉüC= yh¦T  ÄÈ bø õ\n"
          ]
        }
      ]
    }
  ]
}